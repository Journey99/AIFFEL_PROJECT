{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b38b5f9",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기를 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ee28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f569a7b2",
   "metadata": {},
   "source": [
    "### matplotlib\n",
    "- 파이썬에서 제공하는 시각화(Visualization) 라이브러리로 이 프로젝트에서는 training 이미지의 resize가 잘 이루어졌는지 확인하기 위해 사용된다\n",
    "---\n",
    "### os\n",
    "- 운영체제에서 제공되는 여러기능을 파이썬에서 사용할 수 있도록 하는 모듈로 현재 작업하고 있는 디렉토리의 경로를 얻는다\n",
    "---\n",
    "### PIL\n",
    "- 다양한 이미지 파일 형식을 지원하고 강력한 이미지 처리와 그래픽 기능을 제공하는 라이브러리로 이 프로젝트에서는 데이터 이미지의 크기를 줄이기 위해 사용된다\n",
    "---\n",
    "### glob\n",
    "- 파일들의 리스트를 뽑을 때 사용된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76220809",
   "metadata": {},
   "source": [
    "## (1) training set 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ebef36",
   "metadata": {},
   "source": [
    "### resize_images()\n",
    "- 224x224 사이즈의 이미지를 28x28 사이즈의 이미지로 변환\n",
    "- ANTIALIAS : 안티엘리어싱은 한국어로 위신호 제거라는 용어로 높은 해상도의 사진 또는 영상을 낮은 해상도로 변환하거나 나타낼때 깨진 패턴의 형태로 나타나게 되는데 이를 최소화 시켜주는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2f8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d335bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500  images to be resized.\n",
      "1500  images resized.\n",
      "가위 이미지 resize 완료!\n",
      " \n",
      "1500  images to be resized.\n",
      "1500  images resized.\n",
      "바위 이미지 resize 완료\n",
      " \n",
      "1500  images to be resized.\n",
      "1500  images resized.\n",
      "보 이미지 resize 완료!\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor1\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "print(\" \")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock1\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료\")\n",
    "print(\" \")\n",
    "\n",
    "# 보 이미지 변환\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper1\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb412b57",
   "metadata": {},
   "source": [
    "### load_data()\n",
    "- numpy를 이용해서 이미지 데이터와 라벨을 행렬에 저장\n",
    "- dtype=np.int32 : 정수 단일 값을 32bits 메모리에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b10f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 4500 입니다.\n",
      "x_train shape: (4500, 28, 28, 3)\n",
      "y_train shape: (4500,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=4500):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor1/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock1/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper1/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3d180",
   "metadata": {},
   "source": [
    "### 이미지와 라벨 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8446d455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 확인\n",
    "plt.imshow(x_train[15])\n",
    "print('라벨: ', y_train[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31187267",
   "metadata": {},
   "source": [
    "## (2) 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bec7e",
   "metadata": {},
   "source": [
    "###  LeNet\n",
    "- tf.keras의 Sequential API를 이용한 딥러닝 네트워크\n",
    "- Conv2D 레이어\n",
    "    - 첫 번째 인자: 사용하는 이미지 특징의 수. 여기서는 가장 먼저 32개의 이미지 특성을, 그 뒤에는 64개의 이미지 특징을 고려\n",
    "    - 두 번째 인자: 컨볼루션 커널의 (행,열)\n",
    "    - activation : 활성화 함수 설정. 여기서는 'relu' 함수가 쓰였다\n",
    "- Dense 레이어\n",
    "    - 첫 번째 인자: 분류기에 사용되는 뉴런의 숫자. 이 값이 클수록 보다 복잡한 분류기를 만들 수 있다\n",
    "- 마지막 Dense 레이어\n",
    "    - 뉴런 숫자는 결과적으로 분류해 내야 하는 클래스 수로 여기서는 3(가위,바위,보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160b9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a2b86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e9be51",
   "metadata": {},
   "source": [
    "## (3) 딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6afa3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 3s 4ms/step - loss: 1.0589 - accuracy: 0.4700\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7542\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8764\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9327\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9518\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9667\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9778\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9833\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36385004c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45370c",
   "metadata": {},
   "source": [
    "## (4) test set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9793aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 테스트 이미지 resize 완료!\n",
      " \n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 테스트 이미지 resize 완료!\n",
      " \n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 테스트 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 테스트 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 테스트 이미지 resize 완료!\")\n",
    "print(\" \")\n",
    "\n",
    "# 바위 테스트 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 테스트 이미지 resize 완료!\")\n",
    "print(\" \")\n",
    "\n",
    "# 보 테스트 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 테스트 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c34b600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test2\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551ccf25",
   "metadata": {},
   "source": [
    "## (5) Accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f9bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 2.1816 - accuracy: 0.7300\n",
      "test_loss: 2.1816039085388184 \n",
      "test_accuracy: 0.7300000190734863\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a54fa",
   "metadata": {},
   "source": [
    "## (6) 고찰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f6d78d",
   "metadata": {},
   "source": [
    "### 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c70e1",
   "metadata": {},
   "source": [
    "- 훈련 데이터 4500개로 이미지 분류기 모델을 만들고 테스트 데이터 300개로 테스트를 한 결과 test accuracy가 약 0.73이 나왔다\n",
    "- 하지만 test loss가 2.18이 나온 것은 꽤 많이 나온 값인데 이는 모델이 너무 복잡해서 과대적합(Overfitting)이 발생한 걸로 보인다.\n",
    "    - 과대적합 : epoch가 진행되면서 train loss는 계속 감소하지만 test loss가 증가하기 시작함. 모델이 너무 복잡하면 발생하고 좀 더 단순한 모델을 사용하는 것을 생각해 봐야 함. 훈련 데이터에 특화된 패턴을 학습하기 시작하여 새로운 데이터에 대해 잘못된 판단을 함\n",
    "    - 과대적합을 방지하기 위한 방법\n",
    "        - 더 많은 data를 수집\n",
    "        - 모델을 간단하게 바꾼다\n",
    "- 과대적합을 해결하기 위하여 네트워크의 하이퍼파라미터를 n_channel_1=16, n_channel_2=32, Dense의 뉴런 개수=32로 변경하였다.\n",
    "- 변경한 후 결과는 test_loss = 1.55508, test_accuracy = 0.6777으로 test loss는 감소하였지만 test accuracy는 조금 감소했다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4ba2f",
   "metadata": {},
   "source": [
    "---\n",
    "### 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4fe8e",
   "metadata": {},
   "source": [
    "1. train data : 900 / test data : 300 / n_chann1_1 : 16 / n_channel_2 : 32 일 때 0.33\n",
    "2. train data : 900 / test data : 300 / n_chann1_1 : 64 / n_channel_2 : 128 일 때 0.36\n",
    "3. train data : 900 / test data : 300 / n_chann1_1 : 128 / n_channel_2 : 256 일 때 0.31\n",
    "- 하이퍼파라미터의 문제가 아닌것 같아서 데이터의 양을 늘려보았다\n",
    "4. train data : 3138 / test data : 300 / n_channel_1 : 32 / n_channel_2 : 64 일 때 0.33\n",
    "5. train data : 3138 / test data : 300 / n_channel_1 : 128 / n_channel_2 : 256 일 때 0.43\n",
    "- 데이터의 양을 늘려도 개선이 되지 않아서 데이터의 질을 바꾸려고 노력했다. 정확하게 찍힌 사진들로 선정하여 데이터의 질을 좀 더 높이고 양을 조금 늘렸다\n",
    "6. train data : 4500 / test data : 300 / n_channel_1 : 32 / n_channel_2 : 64 드디어 0.73!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63188e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0755b",
   "metadata": {},
   "source": [
    "### 정리\n",
    "- 데이터의 질이 중요하다고 생각이 들었다. 아무리 많은 양의 데이터가 있어도 도움이 되지 못하는 데이터라면 양이 많은게 좋은게 아니다.\n",
    "- 사진마다 배경과 빛 등 다양한 부분에서 차이가 있는데 이런 부분들도 학습이 됐기 때문에 과대적합이 발생한 것 같다 \n",
    "- 테스트할게 많아도 정확도가 떨어진다\n",
    "- 하이퍼파라미터가 너무 커도 너무 많은 특징을 잡아서 좋지 않다\n",
    "- resize를 왜 할까 생각했는데 이미지 사이즈가 크면 학습시간이 오래걸리고 기대했던 것 보다 정확도가 좋지 않았다 \n",
    "- Conv2D레이어와 Maxpooling2D 레이어를 추가하면 정확도가 더 올라간다고 해서 한 쌍, 두 쌍 점점 추가를 해보았지만 너무 많이 추가했을 경우에 오히려 정확도가 떨어졌다. 이 부분은 공부를 더 해야할 것 같다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
